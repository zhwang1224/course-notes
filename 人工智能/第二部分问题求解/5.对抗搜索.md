# 对抗搜索 博弈
## 5.1 博弈
1. 对抗搜索问题——博弈
    1. 有完整信息、确定的、轮流行动、两个参与者、零和游戏
    2. 形式化定义
       1. S0 初始状态
       2. PLAYER(S) 状态s谁行动
       3. ACTION(S) 状态s的合法行动集合
       4. RESULT(S,A)   转移模型， 状态s行动a下的结果
       5. TERMINAL-TEST(S)  终止测试，游戏结束返回真，终止状态
       6. UTILITY(S,P)  效用函数，目标函数

2. 博弈树
   1. 初始状态、ACTION函数、转移模型
   2. 结点-状态 边-移动动作
   3. 构建博弈树不需要效用函数

## 5.2 博弈中的优化决策
1. 极大极小值
   1. MAX玩家选择最大效用
   2. MIN玩家选择最小效用
2. 计算节点效用值
   1. 递归求值，极大极小值

### 5.2.2 多人博弈的最优决策
向量化 <1,2,6> 多人的效用

## 5.3 α-β剪枝
1. α - 当前路径发现的MAX的最大值
2. 同理 β 最小值
3. 不断更新 ab 
4. 当某个节点分别， 比当前MAX的α大 或 比MIN 的β小 ，则剪枝剩下的分支。
![2](/course-notes/人工智能/image/第二部分/2.jpg)

## 蒙特卡洛树搜索
蒙特卡洛树搜索（Monte Carlo Tree Search，MCTS）是一种用于决策问题和游戏的搜索算法，特别适用于大规模搜索空间和不完全信息的情况。MCTS主要用于在树结构中模拟搜索过程，并根据模拟结果进行决策。

MCTS的主要步骤包括：

 - 选择（Selection）： 从根节点开始，根据一定策略（通常是Upper Confidence Bound，UCB）选择一个子节点，直到达到叶子节点。
 
 - 扩展（Expansion）： 对选择的叶子节点进行扩展，生成一个或多个未访问的子节点，代表可能的下一步。

 - 模拟（Simulation）： 针对扩展的子节点，使用随机策略或启发式方法模拟游戏或问题的进行，直到达到终止条件（比如游戏结束）。

 - 回溯（Backpropagation）： 将模拟的结果反向传播到搜索树中，更新每个访问节点的统计信息，比如访问次数和累积收益。

 - 重复（Iteration）： 重复以上步骤，直到达到预定的搜索时间或计算资源。

MCTS通过在搜索树中动态扩展和更新节点，不断优化对不同动作的评估，从而找到一个相对较好的决策。这种方法尤其适用于那些无法在一次搜索中覆盖整个搜索空间的问题，例如棋类游戏和其他决策问题。