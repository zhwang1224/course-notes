
## 3.4 无信息搜索策略
1. 搜索算法的功能
生成后继并区分目标和非目标状态
2. 搜索策略就是如何选择将要扩展的状态，如如何选择frontier的节点决定了算法策略
3. 无信息搜索
   1. 除问题定义中的状态信息外，没有任何附加信息
   2. 盲目搜索
4. 最佳优先搜索（Best-first search） BFS
   1. 选择某个节点n，当评估函数f(n)取最小值时
   2. 每次迭代扩展总是在边缘集中选择一个f(n)最小的节点进行扩展，直到找到目标节点。
   3. 评估函数f(n)的选择，决定了何种搜索策略
5. 宽度优先bfs
   1. 先扩展根结点，扩展根节点的所有后继，依次类推
   2. 特点是按层推进，队列先进先出FIFO，将边缘集组成队列即可
   3. 性能分析  
      1. 完备，有解一定能找到
      2. 不一定最优
      3. 时间复杂度，空间复杂度较高 **O(b^d)**
6. 一致代价搜索（Dijkastra Algorithm） UCS
    1. 宽度优先搜索未考虑路径耗散，默认路径耗散均为1
    2. 基本思路
       1. 优先扩展路径耗散g(n)=g'(n)+n最小的节点 加上之前的路径代价
       2. 通过将边缘集中的节点按积累的g值进行排序来实现(优先级队列)
    3. 搜索步骤
       1. 考察边缘集，选择扩展损耗最小的节点
    4. 算法评价
       1. 完备性，如果每步代价都大于某个小的正常数，则完备，因为如果存在代价0则可能死循环
       2. 最优
       3. 时间复杂度比宽度优先要高，空间复杂度类似
7. 深度优先
   1. 总是扩展当前节点集中最深的节点
   2. 最新生成的边缘节点最早被扩展
   3. 边缘集后进先出LIFO 栈
   4. **算法评价**
      1. 完备性
         1. 图搜索有限状态空间时完备
         2. 树搜索有可能陷入死循环和冗余路径
      2. 不是最优
      3.**时间复杂度类似于宽度优先，空间复杂度具有优势** O(bm)
8. 深度受限搜索 Depth-Limited search 
   1. 为解决无线状态空间下深度优先搜索不完备的问题,不具有完备性和最优性
   2. 深度为L的节点当作没有后继（可用路径代价）
   3. 目标节点深度为d，则L< d则不完备，L>>d则不是最优
   4. 状态空间的直径可视为d
9. 迭代加深的深度优先搜索 ids iterative deepening search
   1.  一个合适的L难以确定，不断加深L的深度限制，从0开始，然后依次类推，直到找到目标。
   2.  算法评价
       1. 分支因子有限时完备
       2. 代价是节点深度的非递减函数时最优
       3. 时间复杂度和宽度优先类似
       4. 空间复杂度和深度优先相近，比宽度好
10. 双向搜索
    1.  从初始状态向前搜索，从目标状态向后搜索
    2.  在中间某个节点相遇，则搜索结束
    3.  存在困难：要求所有动作可逆，目标状态唯一不好解决
11. 无信息搜索策略之间由什么联系？课后题3.17

## 3.5 有信息（启发式）搜索策略
1. 评价函数f(n)
   1. 在最佳优先搜索(一般为启发式)中，f(n)的选择决定了那种策略，无信息搜索使用路径耗散，而启发函数使用最小代价的估计值h(n)。
   2. 如果f(n)由启发函数(heuristic)
      1. f(n)=h(n)=节点n到目标节点最小代价的估计值
2. 启发式函数 heuristic function
   1. **在搜索算法中利用额外信息，提高搜索性能**
   2. 简称启发式h(n)
3. 贪婪最佳优先算法 Greedy best-first search
   1. 基本思想
      1. **总是扩展离目标最近的节点**
      2. 在边缘集对了将节点按距目标距离进行排序
      3. 只考虑启发式信息f(n)=h(n) 一致代价搜索中f(n)是路径耗散之和
   2. 罗马尼亚地图问题应用
      1. 使用直线距离启发式Hsld
        ![fig.3](../image/第一部分/fig3.jpg)
      2. 扩展直线距离最小的节点
      3. 算法评价
         1. 完备性：**可能循环，不完备**
         2. **不是最优**
         3. 时间复杂度：依赖于好的启发式函数，空间和深度优先类似
4. A*搜索
   1. 贪婪算法可能存在的问题
      1. 只考虑眼前
      2. 静态，启发式函数只与状态有关
   2. 基本思想
      1. 启发式：已花费代价+到目标的最小代价估计f(n)=g(n)+h(n)
      2. 此时f(n)=经过节点n的最小代价解的估计代价，算法首先扩展g(n)+h(n)最小的节点
      3. 本质上是**一致代价和贪婪最佳**的结合
        ![fig.4](../image/第一部分/fig4.jpg)
   3. 启发式的可采纳性和一致性
      1. 可采纳性：永远不**过高**估计到达目标的代价，f(n)不超过经过节点n的解的实际代价
      2. 一致性：启发式满足一致性则必然满足可采纳性，到达目的节点的下界
         h(n)<=c(n,a,n')+h(n') 从节点n到目的地的估计代价不大于从n到n'的单步代价与从n'到目的地的代价之和。
      3. 如果h(n)是一致的，则沿着任何路径的f(n)值是非递减的，即若A*选择扩展节点n，则就已经找到了节点n的最优路径。
      4. g(n)+h(n)等值线:
         ![fig.5](../image/第一部分/fig5.jpg)

## 3.6 启发式函数
八数码问题
   1. h1 = 不在位的棋子数 8
   2. h2 = 所有棋子到其目标的距离和 h2=18(曼哈顿距离)
   ![fig.6](../image/第一部分/fig6.jpg)
1. 启发式精准度对性能的影响
   1. 有效分支因子b*, 是深度为d的搜索树为了能包括N+1个节点所必需的分支因子
      1. N+1 = 1 + b* + (b*)^2 + ... + (b*)^d
      2. 良好的启发式会使b*接近1
   2. 使用h2的A*算法树搜索总是比h1效果要好
2. 松弛问题 可采纳启发式
   1. 松弛问题-**减少原问题**的行动限制，得到启发式
   2. 松弛问题是原状态空间的超图 
   3. 罗马尼亚地图问题使用实际距离，减少路径限制 ![fig.7](/人工智能/image/第一部分/fig7.jpg)
   4. 八数码问题：h1即如果AB方块相邻就可以移动，h2A棋子可以直接移动到方块B，得到启发式。![fig.8](/人工智能/image/第一部分/fig8.jpg)
   5. 最好的启发式：h(n) = max{h1(n),h2(n),...,hk(n),}
3. 从子问题出发
   1. 对每个可能的子问题实例存储解代价
4. 从经验中学习
   1. h(n)=c1x1(n)+c2x2(n)